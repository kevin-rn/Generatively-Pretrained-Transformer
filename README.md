# Generatively-Pretrained-Transformer
This repository is designed for educational purposes to aid in learning how to build a Generative Pretrained Transformer (GPT) model. 
It follows the foundational concepts introduced in the paper "Attention is All You Need" and incorporates insights from OpenAI's GPT-2 and GPT-3 architectures.